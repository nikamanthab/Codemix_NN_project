{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5dcc4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import list_datasets, load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "#from pymagnitude import *\n",
    "from nltk import word_tokenize\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dadba03f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymagnitude'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymagnitude\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pymagnitude'"
     ]
    }
   ],
   "source": [
    "from pymagnitude import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06f1aadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [('tamilmixsentiment', None, 'tamil'), \n",
    "        ('offenseval_dravidian', 'tamil', 'tamil'), \n",
    "        ('offenseval_dravidian', 'malayalam', 'malayalam'),\n",
    "        ('offenseval_dravidian', 'kannada', 'kannada'),\n",
    "        ('kan_hope', None, 'kannada'),\n",
    "        #('Shushant/NepaliSentiment', None, 'hindi')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5630837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(tag):\n",
    "    dataset = load_dataset(tag[0], tag[1])\n",
    "    train_df = pd.DataFrame()\n",
    "    val_df = pd.DataFrame()\n",
    "\n",
    "    train_df['text'] = dataset['train']['text']\n",
    "    train_df['label'] = dataset['train']['label']\n",
    "    \n",
    "    val_df['text'] = dataset['validation']['text']\n",
    "    val_df['label'] = dataset['validation']['label']\n",
    "    \n",
    "#     print(\"TRAIN DESCRIPTION:\")\n",
    "#     print(\"Value Counts:\")\n",
    "#     print(train_df['label'].value_counts())\n",
    "          \n",
    "#     print(\"Sample text and label:\")\n",
    "#     for i in range(5):\n",
    "#         idx = random.randint(0, len(train_df))\n",
    "#         sample = train_df.iloc[idx]\n",
    "#         print(\"Text: {}, Label:{}\".format(sample['text'], sample['label']))\n",
    "    return train_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c5a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        # define layers\n",
    "        self.fc1 = nn.Linear(in_features=input_size,out_features=1024)\n",
    "        self.fc2 = nn.Linear(in_features=1024,out_features=output_size)\n",
    "    # define forward function\n",
    "    def forward(self, t):\n",
    "        # fc 1\n",
    "        t=self.fc1(t)\n",
    "        t=F.relu(t)\n",
    "        # fc 2\n",
    "        t=self.fc2(t)\n",
    "        # don't need softmax here since we'll use cross-entropy as activation.\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa9b8577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model, model_type):\n",
    "    if model_type in ['TfidfVectorizer', 'CountVectorizer']:\n",
    "        return model.transform(text).toarray()\n",
    "    elif model_type == 'BERT':\n",
    "        print(\"BERT model embedding...\")\n",
    "        return model.encode(text, batch_size=8, show_progress_bar=True)\n",
    "    elif model_type == 'magnitude':\n",
    "        vectors = []\n",
    "        for sentence in tqdm(text):\n",
    "            vectors.append(np.average(model.query(word_tokenize(sentence)), axis=0))\n",
    "        return vectors    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5defa032",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodemixDataset(Dataset):\n",
    "    def __init__(self, df, encoder_model, encoding_type):\n",
    "        self.df = df\n",
    "        self.embedding = get_embedding(list(self.df['text']), \\\n",
    "                                      encoder_model, encoding_type)\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        text_embedding = self.embedding[idx]\n",
    "        label = self.df.iloc[idx]['label']\n",
    "        sample = {\n",
    "            'text': text_embedding,\n",
    "            'label': label\n",
    "        }\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04824f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(y_true, y_pred):\n",
    "    if torch.cuda.is_available():\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        recall = recall_score(y_true, y_pred, average='weighted')\n",
    "        precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    else:\n",
    "        accuracy = accuracy_score(y_true.cpu(), y_pred.cpu())\n",
    "        f1 = f1_score(y_true.cpu(), y_pred.cpu(), average='weighted')\n",
    "        recall = recall_score(y_true.cpu(), y_pred.cpu(), average='weighted')\n",
    "        precision = precision_score(y_true.cpu(), y_pred.cpu(), average='weighted')\n",
    "    return accuracy, f1, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fbd9afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_architecture, encoder_model, encoding_type, train_df, test_df, epochs, \\\n",
    "          learning_rate, batch_size, log, device):\n",
    "    input_size = get_embedding([train_df.iloc[0]['text']], encoder_model, encoding_type).shape\n",
    "    model = model_architecture(input_size[1], len(train_df['label'].unique())).to(device)\n",
    "    \n",
    "    train_set = CodemixDataset(train_df, encoder_model, encoding_type)\n",
    "    val_set = CodemixDataset(val_df, encoder_model, encoding_type)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        output_labels = torch.Tensor().to(device)\n",
    "        true_labels = torch.Tensor().to(device)\n",
    "        total_loss = 0\n",
    "        for data in tqdm(train_loader):\n",
    "            text, labels = data['text'], data['label']\n",
    "            inputs = text.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.type(torch.float))\n",
    "            predicted_labels = torch.argmax(outputs, dim=1)\n",
    "            #check this\n",
    "            output_labels = torch.cat((output_labels, predicted_labels), 0)\n",
    "            true_labels = torch.cat((true_labels, labels), 0)\n",
    "            loss = criterion(outputs, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        tr_accuracy, tr_f1, tr_recall, tr_precision = get_scores(true_labels, output_labels)\n",
    "        net_train_loss = total_loss/(len(train_loader)*batch_size)\n",
    "        print('Epoch: {}\\t Train Loss: {:.4f} \\t Train F1:{:.2f}'.format(epoch, net_train_loss, tr_f1), end='\\t')\n",
    "        \n",
    "        output_labels = torch.Tensor().to(device)\n",
    "        true_labels = torch.Tensor().to(device)\n",
    "        total_loss = 0\n",
    "        for i, data in enumerate(test_loader, 0):\n",
    "            text, labels = data['text'], data['label']\n",
    "            \n",
    "            inputs = text.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs.type(torch.float))\n",
    "            predicted_labels = torch.argmax(outputs, dim=1)\n",
    "            output_labels = torch.cat((output_labels, predicted_labels), 0)\n",
    "            true_labels = torch.cat((true_labels, labels), 0)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        ts_accuracy, ts_f1, ts_recall, ts_precision = get_scores(true_labels, output_labels)\n",
    "        net_test_loss = total_loss/(len(train_loader)*batch_size)\n",
    "        print('Test Loss: {:.4f} \\t Test F1:{:.2f}'.format(net_test_loss, ts_f1))\n",
    "\n",
    "        if log != None:\n",
    "            log({\n",
    "                    \"train accuracy\": tr_accuracy,\n",
    "                    \"train f1\": tr_f1,\n",
    "                    \"train recall\": tr_recall,\n",
    "                    \"train precision\": tr_precision,\n",
    "                    \n",
    "                    \"test accuarcy\": ts_accuracy,\n",
    "                    \"test f1\": ts_f1,\n",
    "                    \"test recall\": ts_recall,\n",
    "                    \"test precision\": ts_precision,\n",
    "                    \n",
    "                    \"train loss\": net_train_loss,\n",
    "                    \"test loss\": net_test_loss\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21b786be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset offenseval_dravidian (C:\\Users\\deepa\\.cache\\huggingface\\datasets\\offenseval_dravidian\\tamil\\1.0.0\\caf62757ff7f5922e043f21abf68745096b24007c4b79d5b2344ea3a7238563f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67cc30b0057c4125b3e361ebd822e885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5d1f9751c64b01ac9ba3fea9679ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\t Train Loss: 0.0244 \t Train F1:0.70\tTest Loss: 0.0027 \t Test F1:0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepa\\anaconda3\\envs\\nn_project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e7ee39493043bbbb012aa4f0459ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\t Train Loss: 0.0201 \t Train F1:0.74\tTest Loss: 0.0027 \t Test F1:0.73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0816f909850a404984e69ee36d1af846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\t Train Loss: 0.0173 \t Train F1:0.78\tTest Loss: 0.0029 \t Test F1:0.74\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef90cd31bb64e6cac9b6223cecedb8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\t Train Loss: 0.0137 \t Train F1:0.83\tTest Loss: 0.0030 \t Test F1:0.73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac661c813ea4b37a546c341607d041e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\t Train Loss: 0.0096 \t Train F1:0.88\tTest Loss: 0.0034 \t Test F1:0.74\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b459ad175c9a44a791d9407f44be6f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\t Train Loss: 0.0058 \t Train F1:0.94\tTest Loss: 0.0042 \t Test F1:0.73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a39bf206e34dc2878c6e838fa710f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\t Train Loss: 0.0035 \t Train F1:0.97\tTest Loss: 0.0045 \t Test F1:0.73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a46d11b556a474dbb4d1fe2bd7a867b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\t Train Loss: 0.0033 \t Train F1:0.97\tTest Loss: 0.0051 \t Test F1:0.73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677fb2adf02a43f882a4d649f06ebc27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\t Train Loss: 0.0022 \t Train F1:0.98\tTest Loss: 0.0061 \t Test F1:0.73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ce4e9fd766488dbe8bb7183d8e8d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\t Train Loss: 0.0021 \t Train F1:0.98\tTest Loss: 0.0058 \t Test F1:0.73\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "ETA = 0.001\n",
    "BATCH_SIZE = 32\n",
    "tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_df, val_df = get_data(tags[1])\n",
    "# train_df = pd.read_csv('../dataset/dravidian-codemix/tamil_train.tsv', sep='\\t')\n",
    "# val_df = pd.read_csv('../dataset/dravidian-codemix/tamil_dev.tsv', sep='\\t')\n",
    "\n",
    "# tfidf vec\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1,3), max_features=2048)\n",
    "vectorizer.fit(train_df['text'])\n",
    "train(LinearNetwork, vectorizer, 'CountVectorizer', train_df, val_df, epochs=EPOCHS, \\\n",
    "      learning_rate=ETA, batch_size=BATCH_SIZE, log=None, device=tdevice)\n",
    "\n",
    "# # tfidf vec\n",
    "# vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1,3), max_features=2048)\n",
    "# vectorizer.fit(train_df['text'])\n",
    "# train(LinearNetwork, vectorizer, 'TfidfVectorizer', train_df, val_df, epochs=EPOCHS, \\\n",
    "#       learning_rate=ETA, batch_size=BATCH_SIZE, log=None, device=tdevice)\n",
    "\n",
    "# #fasttext - specific language\n",
    "# model = Magnitude(\"../weights/fasttext/{}/{}.magnitude\".format(tags[0][2], tags[0][2]))\n",
    "# train(LinearNetwork, model, 'magnitude', train_df, val_df, epochs=EPOCHS, \\\n",
    "#       learning_rate=ETA, batch_size=BATCH_SIZE, log=None, device=tdevice)\n",
    "\n",
    "# bert - multilingual\n",
    "# model = SentenceTransformer('distiluse-base-multilingual-cased')\n",
    "# train(LinearNetwork, model, 'BERT', train_df, val_df, epochs=EPOCHS, \\\n",
    "#       learning_rate=ETA, batch_size=BATCH_SIZE, log=None, device=tdevice)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa05d923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tdevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c752e4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4941229f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedc72cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
