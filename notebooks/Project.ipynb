{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5dcc4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import list_datasets, load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "#from pymagnitude import *\n",
    "from nltk import word_tokenize\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadba03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymagnitude import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06f1aadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [('tamilmixsentiment', None, 'tamil'), \n",
    "        ('offenseval_dravidian', 'tamil', 'tamil'), \n",
    "        ('offenseval_dravidian', 'malayalam', 'malayalam'),\n",
    "        ('offenseval_dravidian', 'kannada', 'kannada'),\n",
    "        ('kan_hope', None, 'kannada'),\n",
    "        #('Shushant/NepaliSentiment', None, 'hindi')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5630837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(tag):\n",
    "    dataset = load_dataset(tag[0], tag[1])\n",
    "    train_df = pd.DataFrame()\n",
    "    val_df = pd.DataFrame()\n",
    "\n",
    "    train_df['text'] = dataset['train']['text']\n",
    "    train_df['label'] = dataset['train']['label']\n",
    "    \n",
    "    val_df['text'] = dataset['validation']['text']\n",
    "    val_df['label'] = dataset['validation']['label']\n",
    "    \n",
    "#     print(\"TRAIN DESCRIPTION:\")\n",
    "#     print(\"Value Counts:\")\n",
    "#     print(train_df['label'].value_counts())\n",
    "          \n",
    "#     print(\"Sample text and label:\")\n",
    "#     for i in range(5):\n",
    "#         idx = random.randint(0, len(train_df))\n",
    "#         sample = train_df.iloc[idx]\n",
    "#         print(\"Text: {}, Label:{}\".format(sample['text'], sample['label']))\n",
    "    return train_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c5a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        # define layers\n",
    "        self.fc1 = nn.Linear(in_features=input_size,out_features=1024)\n",
    "        self.fc2 = nn.Linear(in_features=1024,out_features=output_size)\n",
    "    # define forward function\n",
    "    def forward(self, t):\n",
    "        # fc 1\n",
    "        t=self.fc1(t)\n",
    "        t=F.relu(t)\n",
    "        # fc 2\n",
    "        t=self.fc2(t)\n",
    "        # don't need softmax here since we'll use cross-entropy as activation.\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa9b8577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model, model_type):\n",
    "    if model_type in ['TfidfVectorizer', 'CountVectorizer']:\n",
    "        return model.transform(text).toarray()\n",
    "    elif model_type == 'BERT':\n",
    "        print(\"BERT model embedding...\")\n",
    "        return model.encode(text, batch_size=8, show_progress_bar=True)\n",
    "    elif model_type == 'magnitude':\n",
    "        vectors = []\n",
    "        for sentence in tqdm(text):\n",
    "            vectors.append(np.average(model.query(word_tokenize(sentence)), axis=0))\n",
    "        return vectors    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5defa032",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodemixDataset(Dataset):\n",
    "    def __init__(self, df, encoder_model, encoding_type):\n",
    "        self.df = df\n",
    "        self.embedding = get_embedding(list(self.df['text']), \\\n",
    "                                      encoder_model, encoding_type)\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        text_embedding = self.embedding[idx]\n",
    "        label = self.df.iloc[idx]['label']\n",
    "        sample = {\n",
    "            'text': text_embedding,\n",
    "            'label': label\n",
    "        }\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04824f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(y_true, y_pred):\n",
    "    if torch.cuda.is_available():\n",
    "        accuracy = accuracy_score(y_true.cpu(), y_pred.cpu())\n",
    "        f1 = f1_score(y_true.cpu(), y_pred.cpu(), average='weighted')\n",
    "        recall = recall_score(y_true.cpu(), y_pred.cpu(), average='weighted')\n",
    "        precision = precision_score(y_true.cpu(), y_pred.cpu(), average='weighted')\n",
    "    else:\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        recall = recall_score(y_true, y_pred, average='weighted')\n",
    "        precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    return accuracy, f1, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fbd9afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_architecture, encoder_model, encoding_type, train_df, test_df, epochs, \\\n",
    "          learning_rate, batch_size, log, device):\n",
    "    input_size = get_embedding([train_df.iloc[0]['text']], encoder_model, encoding_type).shape\n",
    "    model = model_architecture(input_size[1], len(train_df['label'].unique())).to(device)\n",
    "    \n",
    "    train_set = CodemixDataset(train_df, encoder_model, encoding_type)\n",
    "    val_set = CodemixDataset(val_df, encoder_model, encoding_type)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        output_labels = torch.Tensor().to(device)\n",
    "        true_labels = torch.Tensor().to(device)\n",
    "        total_loss = 0\n",
    "        for data in tqdm(train_loader):\n",
    "            text, labels = data['text'], data['label']\n",
    "            inputs = text.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.type(torch.float))\n",
    "            predicted_labels = torch.argmax(outputs, dim=1)\n",
    "            #check this\n",
    "            output_labels = torch.cat((output_labels, predicted_labels), 0)\n",
    "            true_labels = torch.cat((true_labels, labels), 0)\n",
    "            loss = criterion(outputs, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        tr_accuracy, tr_f1, tr_recall, tr_precision = get_scores(true_labels, output_labels)\n",
    "        net_train_loss = total_loss/(len(train_loader)*batch_size)\n",
    "        print('Epoch: {}\\t Train Loss: {:.4f} \\t Train F1:{:.2f}'.format(epoch, net_train_loss, tr_f1), end='\\t')\n",
    "        \n",
    "        output_labels = torch.Tensor().to(device)\n",
    "        true_labels = torch.Tensor().to(device)\n",
    "        total_loss = 0\n",
    "        for i, data in enumerate(test_loader, 0):\n",
    "            text, labels = data['text'], data['label']\n",
    "            \n",
    "            inputs = text.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs.type(torch.float))\n",
    "            predicted_labels = torch.argmax(outputs, dim=1)\n",
    "            output_labels = torch.cat((output_labels, predicted_labels), 0)\n",
    "            true_labels = torch.cat((true_labels, labels), 0)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        ts_accuracy, ts_f1, ts_recall, ts_precision = get_scores(true_labels, output_labels)\n",
    "        net_test_loss = total_loss/(len(train_loader)*batch_size)\n",
    "        print('Test Loss: {:.4f} \\t Test F1:{:.2f}'.format(net_test_loss, ts_f1))\n",
    "\n",
    "        if log != None:\n",
    "            log({\n",
    "                    \"train accuracy\": tr_accuracy,\n",
    "                    \"train f1\": tr_f1,\n",
    "                    \"train recall\": tr_recall,\n",
    "                    \"train precision\": tr_precision,\n",
    "                    \n",
    "                    \"test accuarcy\": ts_accuracy,\n",
    "                    \"test f1\": ts_f1,\n",
    "                    \"test recall\": ts_recall,\n",
    "                    \"test precision\": ts_precision,\n",
    "                    \n",
    "                    \"train loss\": net_train_loss,\n",
    "                    \"test loss\": net_test_loss\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21b786be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:z2ew3l8y) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95bd7931cc484b938b26354d96c6225c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test accuarcy</td><td>▇██▅▃▂▄▁▄▂</td></tr><tr><td>test f1</td><td>▁█▆█▇▆▆▇▇▆</td></tr><tr><td>test loss</td><td>▁▁▂▂▃▅▅▆▇█</td></tr><tr><td>test precision</td><td>▁█▄█▅▃▄▇▅▃</td></tr><tr><td>test recall</td><td>▇██▅▃▂▄▁▄▂</td></tr><tr><td>train accuracy</td><td>▁▂▃▄▅▇▇███</td></tr><tr><td>train f1</td><td>▁▂▃▄▆▇▇███</td></tr><tr><td>train loss</td><td>█▇▆▅▄▂▂▁▁▁</td></tr><tr><td>train precision</td><td>▁▂▃▄▆▇▇███</td></tr><tr><td>train recall</td><td>▁▂▃▄▅▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test accuarcy</td><td>0.74521</td></tr><tr><td>test f1</td><td>0.72798</td></tr><tr><td>test loss</td><td>0.00598</td></tr><tr><td>test precision</td><td>0.71691</td></tr><tr><td>test recall</td><td>0.74521</td></tr><tr><td>train accuracy</td><td>0.98782</td></tr><tr><td>train f1</td><td>0.9878</td></tr><tr><td>train loss</td><td>0.0015</td></tr><tr><td>train precision</td><td>0.98779</td></tr><tr><td>train recall</td><td>0.98782</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">breezy-sky-1</strong>: <a href=\"https://wandb.ai/nnproj/nn-project2/runs/z2ew3l8y\" target=\"_blank\">https://wandb.ai/nnproj/nn-project2/runs/z2ew3l8y</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220420_181148-z2ew3l8y\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:z2ew3l8y). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\deepa\\Documents\\Files\\MSinUS\\OSU\\projects\\nnet\\final_project\\codemix\\notebooks\\wandb\\run-20220420_181903-1pkrzokn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nnproj/nn-project2/runs/1pkrzokn\" target=\"_blank\">drawn-aardvark-2</a></strong> to <a href=\"https://wandb.ai/nnproj/nn-project2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset offenseval_dravidian (C:\\Users\\deepa\\.cache\\huggingface\\datasets\\offenseval_dravidian\\tamil\\1.0.0\\caf62757ff7f5922e043f21abf68745096b24007c4b79d5b2344ea3a7238563f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4c583d175246e3a4e107b3acd7da9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e19812266ac4e748f3a02509915163d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepa\\anaconda3\\envs\\nn_project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\t Train Loss: 0.0243 \t Train F1:0.69\tTest Loss: 0.0028 \t Test F1:0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepa\\anaconda3\\envs\\nn_project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d67fa27c5ff44b2847bee4a541b761a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\t Train Loss: 0.0201 \t Train F1:0.74\tTest Loss: 0.0029 \t Test F1:0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepa\\anaconda3\\envs\\nn_project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a50e6572de34d2d991a724ddebcc64a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\t Train Loss: 0.0173 \t Train F1:0.78\tTest Loss: 0.0030 \t Test F1:0.73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e5a15d443a4cc9841c4ffdbc5d349b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\t Train Loss: 0.0135 \t Train F1:0.84\tTest Loss: 0.0034 \t Test F1:0.73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c301a3bc60994c0bb5ff1d629e8d2197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\t Train Loss: 0.0095 \t Train F1:0.90\tTest Loss: 0.0039 \t Test F1:0.72\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0bff61b21b457aa503656b37930d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\t Train Loss: 0.0064 \t Train F1:0.93\tTest Loss: 0.0045 \t Test F1:0.72\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7dc4e1ac0f46618d12d58e3975cbc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\t Train Loss: 0.0044 \t Train F1:0.96\tTest Loss: 0.0050 \t Test F1:0.73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82113f00225d40049f2bfe1cde6095d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\t Train Loss: 0.0032 \t Train F1:0.97\tTest Loss: 0.0055 \t Test F1:0.72\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31e359e07794c859d2e97ed199e4843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\t Train Loss: 0.0027 \t Train F1:0.98\tTest Loss: 0.0060 \t Test F1:0.72\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa447b3f0bcc4cc886b8341837551e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\t Train Loss: 0.0023 \t Train F1:0.98\tTest Loss: 0.0063 \t Test F1:0.72\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff616ea2c3504755806a9ee2be3089fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test accuarcy</td><td>█▆▅▅▁▂▃▃▂▂</td></tr><tr><td>test f1</td><td>▁▆█▅▅▄▆▄▂▂</td></tr><tr><td>test loss</td><td>▁▁▁▂▃▄▅▆▇█</td></tr><tr><td>test precision</td><td>▇█▇▃▄▃▅▃▁▂</td></tr><tr><td>test recall</td><td>█▆▅▅▁▂▃▃▂▂</td></tr><tr><td>train accuracy</td><td>▁▂▃▄▆▇▇███</td></tr><tr><td>train f1</td><td>▁▂▃▅▆▇████</td></tr><tr><td>train loss</td><td>█▇▆▅▃▂▂▁▁▁</td></tr><tr><td>train precision</td><td>▁▂▃▅▆▇████</td></tr><tr><td>train recall</td><td>▁▂▃▄▆▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test accuarcy</td><td>0.74567</td></tr><tr><td>test f1</td><td>0.71907</td></tr><tr><td>test loss</td><td>0.00634</td></tr><tr><td>test precision</td><td>0.70559</td></tr><tr><td>test recall</td><td>0.74567</td></tr><tr><td>train accuracy</td><td>0.97817</td></tr><tr><td>train f1</td><td>0.97801</td></tr><tr><td>train loss</td><td>0.00229</td></tr><tr><td>train precision</td><td>0.97803</td></tr><tr><td>train recall</td><td>0.97817</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">drawn-aardvark-2</strong>: <a href=\"https://wandb.ai/nnproj/nn-project2/runs/1pkrzokn\" target=\"_blank\">https://wandb.ai/nnproj/nn-project2/runs/1pkrzokn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220420_181903-1pkrzokn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "ETA = 0.001\n",
    "BATCH_SIZE = 32\n",
    "tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "run = wandb.init(project=\"nn-project2\", entity=\"nnproj\",reinit=True)\n",
    "\n",
    "train_df, val_df = get_data(tags[1])\n",
    "# train_df = pd.read_csv('../dataset/dravidian-codemix/tamil_train.tsv', sep='\\t')\n",
    "# val_df = pd.read_csv('../dataset/dravidian-codemix/tamil_dev.tsv', sep='\\t')\n",
    "\n",
    "# tfidf vec\n",
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1,3), max_features=2048)\n",
    "vectorizer.fit(train_df['text'])\n",
    "train(LinearNetwork, vectorizer, 'CountVectorizer', train_df, val_df, epochs=EPOCHS, \\\n",
    "      learning_rate=ETA, batch_size=BATCH_SIZE, log=wandb.log, device=tdevice)\n",
    "\n",
    "# # tfidf vec\n",
    "# vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1,3), max_features=2048)\n",
    "# vectorizer.fit(train_df['text'])\n",
    "# train(LinearNetwork, vectorizer, 'TfidfVectorizer', train_df, val_df, epochs=EPOCHS, \\\n",
    "#       learning_rate=ETA, batch_size=BATCH_SIZE, log=None, device=tdevice)\n",
    "\n",
    "# #fasttext - specific language\n",
    "# model = Magnitude(\"../weights/fasttext/{}/{}.magnitude\".format(tags[0][2], tags[0][2]))\n",
    "# train(LinearNetwork, model, 'magnitude', train_df, val_df, epochs=EPOCHS, \\\n",
    "#       learning_rate=ETA, batch_size=BATCH_SIZE, log=None, device=tdevice)\n",
    "\n",
    "# bert - multilingual\n",
    "# model = SentenceTransformer('distiluse-base-multilingual-cased')\n",
    "# train(LinearNetwork, model, 'BERT', train_df, val_df, epochs=EPOCHS, \\\n",
    "#       learning_rate=ETA, batch_size=BATCH_SIZE, log=None, device=tdevice)\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa05d923",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tdevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c752e4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4941229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fedc72cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_analyzer = [\"char\",\"word\"]\n",
    "ngram_ranges = [(1,3),(2,5)]\n",
    "ngram_maxfeatures = [1000, 2000, 5000, 10000]\n",
    "# mlp_layers = [2,4]\n",
    "mlp_dropout=[0,0.25]\n",
    "mlp_hiddenNodes = [1024, 2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2fa0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp_config = [\n",
    "#     {\n",
    "#         'layers': 2,\n",
    "#         'dropout':[0,0.25]\n",
    "#         'hiddenNodes':[1024, 2048]\n",
    "#     }\n",
    "    \n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdd93ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_1-3_1000_2L_0D_1024\n",
      "char_1-3_1000_2L_0D_2048\n",
      "char_1-3_1000_2L_0.25D_1024\n",
      "char_1-3_1000_2L_0.25D_2048\n",
      "char_1-3_2000_2L_0D_1024\n",
      "char_1-3_2000_2L_0D_2048\n",
      "char_1-3_2000_2L_0.25D_1024\n",
      "char_1-3_2000_2L_0.25D_2048\n",
      "char_1-3_5000_2L_0D_1024\n",
      "char_1-3_5000_2L_0D_2048\n",
      "char_1-3_5000_2L_0.25D_1024\n",
      "char_1-3_5000_2L_0.25D_2048\n",
      "char_1-3_10000_2L_0D_1024\n",
      "char_1-3_10000_2L_0D_2048\n",
      "char_1-3_10000_2L_0.25D_1024\n",
      "char_1-3_10000_2L_0.25D_2048\n",
      "char_2-5_1000_2L_0D_1024\n",
      "char_2-5_1000_2L_0D_2048\n",
      "char_2-5_1000_2L_0.25D_1024\n",
      "char_2-5_1000_2L_0.25D_2048\n",
      "char_2-5_2000_2L_0D_1024\n",
      "char_2-5_2000_2L_0D_2048\n",
      "char_2-5_2000_2L_0.25D_1024\n",
      "char_2-5_2000_2L_0.25D_2048\n",
      "char_2-5_5000_2L_0D_1024\n",
      "char_2-5_5000_2L_0D_2048\n",
      "char_2-5_5000_2L_0.25D_1024\n",
      "char_2-5_5000_2L_0.25D_2048\n",
      "char_2-5_10000_2L_0D_1024\n",
      "char_2-5_10000_2L_0D_2048\n",
      "char_2-5_10000_2L_0.25D_1024\n",
      "char_2-5_10000_2L_0.25D_2048\n",
      "word_1-3_1000_2L_0D_1024\n",
      "word_1-3_1000_2L_0D_2048\n",
      "word_1-3_1000_2L_0.25D_1024\n",
      "word_1-3_1000_2L_0.25D_2048\n",
      "word_1-3_2000_2L_0D_1024\n",
      "word_1-3_2000_2L_0D_2048\n",
      "word_1-3_2000_2L_0.25D_1024\n",
      "word_1-3_2000_2L_0.25D_2048\n",
      "word_1-3_5000_2L_0D_1024\n",
      "word_1-3_5000_2L_0D_2048\n",
      "word_1-3_5000_2L_0.25D_1024\n",
      "word_1-3_5000_2L_0.25D_2048\n",
      "word_1-3_10000_2L_0D_1024\n",
      "word_1-3_10000_2L_0D_2048\n",
      "word_1-3_10000_2L_0.25D_1024\n",
      "word_1-3_10000_2L_0.25D_2048\n",
      "word_2-5_1000_2L_0D_1024\n",
      "word_2-5_1000_2L_0D_2048\n",
      "word_2-5_1000_2L_0.25D_1024\n",
      "word_2-5_1000_2L_0.25D_2048\n",
      "word_2-5_2000_2L_0D_1024\n",
      "word_2-5_2000_2L_0D_2048\n",
      "word_2-5_2000_2L_0.25D_1024\n",
      "word_2-5_2000_2L_0.25D_2048\n",
      "word_2-5_5000_2L_0D_1024\n",
      "word_2-5_5000_2L_0D_2048\n",
      "word_2-5_5000_2L_0.25D_1024\n",
      "word_2-5_5000_2L_0.25D_2048\n",
      "word_2-5_10000_2L_0D_1024\n",
      "word_2-5_10000_2L_0D_2048\n",
      "word_2-5_10000_2L_0.25D_1024\n",
      "word_2-5_10000_2L_0.25D_2048\n"
     ]
    }
   ],
   "source": [
    "for na in ngram_analyzer:\n",
    "    for nr in ngram_ranges:\n",
    "        for nmf in ngram_maxfeatures:\n",
    "            for dp in mlp_dropout:\n",
    "                for hn in mlp_hiddenNodes:\n",
    "                    name = na+\"_\"+str(nr[0])+\"-\"+str(nr[1])+\"_\"+str(nmf)+\"_2L_\"+str(dp)+\"D_\"+str(hn)\n",
    "                    print(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
