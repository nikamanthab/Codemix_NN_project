{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5dcc4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import list_datasets, load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "#from pymagnitude import *\n",
    "from nltk import word_tokenize\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadba03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymagnitude import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06f1aadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [('tamilmixsentiment', None, 'tamil'), \n",
    "        ('offenseval_dravidian', 'tamil', 'tamil'), \n",
    "        ('offenseval_dravidian', 'malayalam', 'malayalam'),\n",
    "        ('offenseval_dravidian', 'kannada', 'kannada'),\n",
    "        ('kan_hope', None, 'kannada'),\n",
    "        #('Shushant/NepaliSentiment', None, 'hindi')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5630837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(tag):\n",
    "    dataset = load_dataset(tag[0], tag[1])\n",
    "    train_df = pd.DataFrame()\n",
    "    val_df = pd.DataFrame()\n",
    "\n",
    "    train_df['text'] = dataset['train']['text']\n",
    "    train_df['label'] = dataset['train']['label']\n",
    "    \n",
    "    val_df['text'] = dataset['validation']['text']\n",
    "    val_df['label'] = dataset['validation']['label']\n",
    "    \n",
    "#     print(\"TRAIN DESCRIPTION:\")\n",
    "#     print(\"Value Counts:\")\n",
    "#     print(train_df['label'].value_counts())\n",
    "          \n",
    "#     print(\"Sample text and label:\")\n",
    "#     for i in range(5):\n",
    "#         idx = random.randint(0, len(train_df))\n",
    "#         sample = train_df.iloc[idx]\n",
    "#         print(\"Text: {}, Label:{}\".format(sample['text'], sample['label']))\n",
    "    return train_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c5a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        # define layers\n",
    "        self.fc1 = nn.Linear(in_features=input_size,out_features=1024)\n",
    "        self.fc2 = nn.Linear(in_features=1024,out_features=output_size)\n",
    "    # define forward function\n",
    "    def forward(self, t):\n",
    "        # fc 1\n",
    "        t=self.fc1(t)\n",
    "        t=F.relu(t)\n",
    "        # fc 2\n",
    "        t=self.fc2(t)\n",
    "        # don't need softmax here since we'll use cross-entropy as activation.\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa9b8577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model, model_type):\n",
    "    if model_type in ['TfidfVectorizer', 'CountVectorizer']:\n",
    "        return model.transform(text).toarray()\n",
    "    elif model_type == 'BERT':\n",
    "        print(\"BERT model embedding...\")\n",
    "        return model.encode(text, batch_size=8, show_progress_bar=True)\n",
    "    elif model_type == 'magnitude':\n",
    "        vectors = []\n",
    "        for sentence in tqdm(text):\n",
    "            vectors.append(np.average(model.query(word_tokenize(sentence)), axis=0))\n",
    "        return vectors    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5defa032",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodemixDataset(Dataset):\n",
    "    def __init__(self, df, encoder_model, encoding_type):\n",
    "        self.df = df\n",
    "        self.embedding = get_embedding(list(self.df['text']), \\\n",
    "                                      encoder_model, encoding_type)\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        text_embedding = self.embedding[idx]\n",
    "        label = self.df.iloc[idx]['label']\n",
    "        sample = {\n",
    "            'text': text_embedding,\n",
    "            'label': label\n",
    "        }\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04824f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(y_true, y_pred):\n",
    "    if torch.cuda.is_available():\n",
    "        accuracy = accuracy_score(y_true.cpu(), y_pred.cpu())\n",
    "        f1 = f1_score(y_true.cpu(), y_pred.cpu(), average='weighted')\n",
    "        recall = recall_score(y_true.cpu(), y_pred.cpu(), average='weighted')\n",
    "        precision = precision_score(y_true.cpu(), y_pred.cpu(), average='weighted')\n",
    "    else:\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        recall = recall_score(y_true, y_pred, average='weighted')\n",
    "        precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    return accuracy, f1, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fbd9afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_architecture, encoder_model, encoding_type, train_df, test_df, epochs, \\\n",
    "          learning_rate, batch_size, log, device):\n",
    "    input_size = get_embedding([train_df.iloc[0]['text']], encoder_model, encoding_type).shape\n",
    "    model = model_architecture(input_size[1], len(train_df['label'].unique())).to(device)\n",
    "    \n",
    "    train_set = CodemixDataset(train_df, encoder_model, encoding_type)\n",
    "    val_set = CodemixDataset(val_df, encoder_model, encoding_type)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        output_labels = torch.Tensor().to(device)\n",
    "        true_labels = torch.Tensor().to(device)\n",
    "        total_loss = 0\n",
    "        for data in tqdm(train_loader):\n",
    "            text, labels = data['text'], data['label']\n",
    "            inputs = text.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs.type(torch.float))\n",
    "            predicted_labels = torch.argmax(outputs, dim=1)\n",
    "            #check this\n",
    "            output_labels = torch.cat((output_labels, predicted_labels), 0)\n",
    "            true_labels = torch.cat((true_labels, labels), 0)\n",
    "            loss = criterion(outputs, labels.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        tr_accuracy, tr_f1, tr_recall, tr_precision = get_scores(true_labels, output_labels)\n",
    "        net_train_loss = total_loss/(len(train_loader)*batch_size)\n",
    "        print('Epoch: {}\\t Train Loss: {:.4f} \\t Train F1:{:.2f}'.format(epoch, net_train_loss, tr_f1), end='\\t')\n",
    "        \n",
    "        output_labels = torch.Tensor().to(device)\n",
    "        true_labels = torch.Tensor().to(device)\n",
    "        total_loss = 0\n",
    "        for i, data in enumerate(test_loader, 0):\n",
    "            text, labels = data['text'], data['label']\n",
    "            \n",
    "            inputs = text.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs.type(torch.float))\n",
    "            predicted_labels = torch.argmax(outputs, dim=1)\n",
    "            output_labels = torch.cat((output_labels, predicted_labels), 0)\n",
    "            true_labels = torch.cat((true_labels, labels), 0)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        ts_accuracy, ts_f1, ts_recall, ts_precision = get_scores(true_labels, output_labels)\n",
    "        net_test_loss = total_loss/(len(train_loader)*batch_size)\n",
    "        print('Test Loss: {:.4f} \\t Test F1:{:.2f}'.format(net_test_loss, ts_f1))\n",
    "\n",
    "        if log != None:\n",
    "            log({\n",
    "                    \"train accuracy\": tr_accuracy,\n",
    "                    \"train f1\": tr_f1,\n",
    "                    \"train recall\": tr_recall,\n",
    "                    \"train precision\": tr_precision,\n",
    "                    \n",
    "                    \"test accuarcy\": ts_accuracy,\n",
    "                    \"test f1\": ts_f1,\n",
    "                    \"test recall\": ts_recall,\n",
    "                    \"test precision\": ts_precision,\n",
    "                    \n",
    "                    \"train loss\": net_train_loss,\n",
    "                    \"test loss\": net_test_loss\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b786be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2d5u7oe4) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f77effc84b4948bda29d20e5ee15d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test accuarcy</td><td>▅▇██▄▃▃▁▂▄</td></tr><tr><td>test f1</td><td>▁▄▅▇▇██▇▅▆</td></tr><tr><td>test loss</td><td>▁▁▁▁▂▃▄▅▇█</td></tr><tr><td>test precision</td><td>▁▇▄▅▆██▇▃▄</td></tr><tr><td>test recall</td><td>▅▇██▄▃▃▁▂▄</td></tr><tr><td>train accuracy</td><td>▁▂▃▄▅▇████</td></tr><tr><td>train f1</td><td>▁▂▃▄▆▇████</td></tr><tr><td>train loss</td><td>█▇▆▅▃▂▁▁▁▁</td></tr><tr><td>train precision</td><td>▁▂▃▄▆▇████</td></tr><tr><td>train recall</td><td>▁▂▃▄▅▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test accuarcy</td><td>0.75684</td></tr><tr><td>test f1</td><td>0.73195</td></tr><tr><td>test loss</td><td>0.00633</td></tr><tr><td>test precision</td><td>0.71618</td></tr><tr><td>test recall</td><td>0.75684</td></tr><tr><td>train accuracy</td><td>0.98179</td></tr><tr><td>train f1</td><td>0.98175</td></tr><tr><td>train loss</td><td>0.00215</td></tr><tr><td>train precision</td><td>0.98173</td></tr><tr><td>train recall</td><td>0.98179</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fearless-sunset-1</strong>: <a href=\"https://wandb.ai/nnproj/nn-project/runs/2d5u7oe4\" target=\"_blank\">https://wandb.ai/nnproj/nn-project/runs/2d5u7oe4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220420_180143-2d5u7oe4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2d5u7oe4). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\deepa\\Documents\\Files\\MSinUS\\OSU\\projects\\nnet\\final_project\\codemix\\notebooks\\wandb\\run-20220420_181148-z2ew3l8y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/nnproj/nn-project2/runs/z2ew3l8y\" target=\"_blank\">breezy-sky-1</a></strong> to <a href=\"https://wandb.ai/nnproj/nn-project2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset offenseval_dravidian (C:\\Users\\deepa\\.cache\\huggingface\\datasets\\offenseval_dravidian\\tamil\\1.0.0\\caf62757ff7f5922e043f21abf68745096b24007c4b79d5b2344ea3a7238563f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91494302e1374e09846d20defe50c9e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d40b3aabaa94fb5a046632697d42f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1099 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "ETA = 0.001\n",
    "BATCH_SIZE = 32\n",
    "tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "run = wandb.init(project=\"nn-project2\", entity=\"nnproj\",reinit=True)\n",
    "\n",
    "train_df, val_df = get_data(tags[1])\n",
    "# train_df = pd.read_csv('../dataset/dravidian-codemix/tamil_train.tsv', sep='\\t')\n",
    "# val_df = pd.read_csv('../dataset/dravidian-codemix/tamil_dev.tsv', sep='\\t')\n",
    "\n",
    "# tfidf vec\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1,3), max_features=2048)\n",
    "vectorizer.fit(train_df['text'])\n",
    "train(LinearNetwork, vectorizer, 'CountVectorizer', train_df, val_df, epochs=EPOCHS, \\\n",
    "      learning_rate=ETA, batch_size=BATCH_SIZE, log=wandb.log, device=tdevice)\n",
    "\n",
    "# # tfidf vec\n",
    "# vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1,3), max_features=2048)\n",
    "# vectorizer.fit(train_df['text'])\n",
    "# train(LinearNetwork, vectorizer, 'TfidfVectorizer', train_df, val_df, epochs=EPOCHS, \\\n",
    "#       learning_rate=ETA, batch_size=BATCH_SIZE, log=None, device=tdevice)\n",
    "\n",
    "# #fasttext - specific language\n",
    "# model = Magnitude(\"../weights/fasttext/{}/{}.magnitude\".format(tags[0][2], tags[0][2]))\n",
    "# train(LinearNetwork, model, 'magnitude', train_df, val_df, epochs=EPOCHS, \\\n",
    "#       learning_rate=ETA, batch_size=BATCH_SIZE, log=None, device=tdevice)\n",
    "\n",
    "# bert - multilingual\n",
    "# model = SentenceTransformer('distiluse-base-multilingual-cased')\n",
    "# train(LinearNetwork, model, 'BERT', train_df, val_df, epochs=EPOCHS, \\\n",
    "#       learning_rate=ETA, batch_size=BATCH_SIZE, log=None, device=tdevice)\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa05d923",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tdevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c752e4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4941229f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedc72cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
